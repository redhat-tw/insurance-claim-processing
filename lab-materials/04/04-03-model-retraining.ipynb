{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8cbdac0-3371-48af-aaa9-c40bbbcb62ff",
   "metadata": {},
   "source": [
    "# 重新訓練 YOLO 模型\n",
    "\n",
    "本 Lab 將重新訓練 YOLO 模型識別車禍車輛，因此需要準備一些帶有中度或嚴重事故標籤的車輛圖片資料集。這邊可以從 `RoboFlow(https://roboflow.com/)`取得資料集，該資料集包含註解的圖片，並分成`訓練`資料集與`驗證`資料集。我們將使用這些資料來重新訓練 YOLO 模型。以下是訓練資料所需資料結構資訊:\n",
    "\n",
    "1. 教我們的模型識別的對象 Encode classes，e.g. 0 - \"中度事故\"、1 - \"嚴重事故\"。\n",
    "2. 資料集將位於目錄中的兩個子目錄，分別為 `train` 與 `valid`。每個子目錄內都包含 `images` 與 `labels` 目錄。\n",
    "3. 每張圖片在 `labels` 目錄中，都有對應的註解文字檔案。註解文字檔案與圖片檔案名稱一致。\n",
    "4. 資料集 `data.yaml` 檔案指向資料集，並描述其中的物件類別，該 YAML 檔將傳遞給模型進行重新訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e0c59-42b1-4de4-9de2-d0875cf597c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you did not use the Workbench image designed for this Lab, you can uncomment and run the following line to install the required packages.\n",
    "# !pip install --no-cache-dir --no-dependencies -r requirements.txt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc755b4b-db03-4b43-9da9-80ed8298417b",
   "metadata": {},
   "source": [
    "接下來載入 YOLO 模型 `yolo8m.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e595eb2-0e11-4dce-9d5c-2a2025ddcd6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = YOLO('yolov8m.pt')  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d43616-2d25-419b-bd30-47a5aafb0d33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 獲取訓練資料\n",
    "\n",
    "以下提供了兩個訓練資料集，以 zip 檔案的形式提供：\n",
    "\n",
    "1. `accident-full.zip` - 用於完全重新訓練模型。\n",
    "2. `accident-sample.zip` - 用於當沒有時間完全重新訓練模型時，進行部分重新訓練模型。\n",
    "\n",
    "在本 Lab 我們僅使用 accident-sample.zip 資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657ceae-db2d-4d65-ae1c-e807254ee71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to retrieve a specific dataset\n",
    "def retrieve_dataset(dataset_type):\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(\"./datasets/\"):\n",
    "        os.makedirs(\"./datasets/\")\n",
    "\n",
    "    URL = f\"https://rhods-public.s3.amazonaws.com/sample-data/accident-data/accident-{dataset_type}.zip\"\n",
    "\n",
    "    # Check if the file exists, if not, download and unzip it\n",
    "    if not os.path.exists(f\"./datasets/accident-{dataset_type}.zip\"):\n",
    "        print(\"Downloading file...\")\n",
    "        response = requests.get(URL, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        t = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "        with open(f'./datasets/accident-{dataset_type}.zip', 'wb') as f:\n",
    "            for data in response.iter_content(block_size):\n",
    "                t.update(len(data))\n",
    "                f.write(data)\n",
    "        t.close()\n",
    "    if os.path.exists(f\"./datasets/accident-{dataset_type}.zip\"):\n",
    "        print(\"Unzipping file...\")\n",
    "        with zipfile.ZipFile(f'./datasets/accident-{dataset_type}.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall(path='./datasets/')\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "dataset_type = 'sample'\n",
    "# dataset_type = 'full' # Use this line instead if you want to retrieve the full dataset\n",
    "retrieve_dataset(dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7d5b4-4c29-4eff-b1ba-a9dddf382173",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 重新訓練自己的 YOLO 模型\n",
    "\n",
    "首先要先了解什麼是 `epoch`。機器學習魔時是透過特定資料集傳遞到演算法進行訓練的。每次完整資料集通過演算法都被稱為完成一個 `epoch`，每個 `epoch` 將進一步改進模型的訓練。\n",
    "\n",
    "在下面的程式碼中，將設置各種參數：\n",
    "\n",
    "```python\n",
    "results = model.train(data='./datasets/accident-sample/data.yaml', epochs=1, imgsz=640, batch=2)\n",
    "```\n",
    "\n",
    "* `epochs`: 由於這邊只是想驗證過程，因此只設定 1 個 epoch。\n",
    "* `imgsz`: 模型需要被匯入的圖片大小(Size)。\n",
    "* `batch`: 演算法將同時處理的圖片數量。數量越多，則結果越好，但消耗更多資源(e.g. RAM)。這邊由於 Lab 限制我們調整為 2 做驗證。\n",
    "\n",
    "在訓練執行中，每個 epoch 都會顯示訓練與驗證階段的摘要：\n",
    "\n",
    "* 第一與第二行顯示訓練階段結果。\n",
    "* 第三與第四行顯示每個 epoch 的驗證階段結果。\n",
    "\n",
    "在你的訓練運行中，每個epoch都會顯示訓練和驗證階段的摘要：第 1 和第 2 行顯示訓練階段的結果，第 3 和第 4 行顯示每個 epoch 的驗證階段的結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22954895-0c26-4ae0-93c1-259efd18e47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "results = model.train(data='./datasets/accident-sample/data.yaml', epochs=1, imgsz=640, batch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45050c91-fb6c-4f14-a4d1-e72d3a40538f",
   "metadata": {},
   "source": [
    "P.S. 在標準的重新訓練後，如果對結果滿意，即可將模型匯出為 ONNX 格式。\n",
    "（，您將 trainX 替換為您想使用的訓練會話）\n",
    "\n",
    "以下指令中，可以將 `trainX` 替換為想使用的訓練 Session\n",
    "\n",
    "```python\n",
    "ObjDetOXModel = YOLO(\"runs/detect/trainX/weights/best.pt\").export(format=\"onnx\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f7412-0b9b-46d1-b2f6-ded479b20cb7",
   "metadata": {},
   "source": [
    "對於使用完整資料集進行訓練的過程，以及結果的完整描述，可以參考 Lab 說明。\n",
    "\n",
    "現在已經重新訓練了 YOLO 模型，這時透過 `04-04-accident-recog.ipynb` 範例對模型進行測試，以驗證其可偵測車禍車輛。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
